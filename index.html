<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Rasmus Puggaard-Rode &amp; James Kirby">
<meta name="dcterms.date" content="2025-05-13">

<title>PraatSauce workflow and parameters</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="index_files/libs/clipboard/clipboard.min.js"></script>
<script src="index_files/libs/quarto-html/quarto.js"></script>
<script src="index_files/libs/quarto-html/popper.min.js"></script>
<script src="index_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="index_files/libs/quarto-html/anchor.min.js"></script>
<link href="index_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="index_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="index_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="index_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="index_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#basic-workflow" id="toc-basic-workflow" class="nav-link active" data-scroll-target="#basic-workflow">Basic workflow</a></li>
  <li><a href="#parameters" id="toc-parameters" class="nav-link" data-scroll-target="#parameters">Parameters</a></li>
  <li><a href="#output" id="toc-output" class="nav-link" data-scroll-target="#output">Output</a></li>
  <li><a href="#details" id="toc-details" class="nav-link" data-scroll-target="#details">Details</a></li>
  <li><a href="#workflow-in-r" id="toc-workflow-in-r" class="nav-link" data-scroll-target="#workflow-in-r">Workflow in R</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">PraatSauce workflow and parameters</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Rasmus Puggaard-Rode &amp; James Kirby </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 13, 2025</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="basic-workflow" class="level2">
<h2 class="anchored" data-anchor-id="basic-workflow">Basic workflow</h2>
<p>When you download <code>praatsauce</code>, all source code is in the <code>src</code> directory. This directory contains the files <code>params.csv</code>, <code>praatsauce.praat</code>, and a whole bunch of other files with Praat scripts that are called by <code>praatsauce.praat</code>. Unlike in previous versions of PraatSauce, you don’t set parameters directly in Praat, but instead by editing the <code>params.csv</code> file, which you can do in any text editor or in a spreadsheet editor like Excel if you prefer. When you run <code>praatsauce.praat</code>, a form will appear asking you only for the location of your parameters file. We think this is advantageous in terms of reproducibility, as you can simply share this parameters file when sharing the code for a study.</p>
<p>This set-up also means that calling PraatSauce from the command line is very simple:</p>
<pre><code>&lt;praat-location&gt; &lt;praatsauce-location&gt; &lt;params-location&gt;</code></pre>
<p>where <code>&lt;praat-location&gt;</code> is the location of your Praat executable, <code>&lt;praatsauce-location&gt;</code> is the path to <code>praatsauce.praat</code>, and <code>&lt;params-location&gt;</code> is the path to your parameters file. If Praat is on your <code>PATH</code> and you are running the code directly from the <code>src</code> directory, it could look like this:</p>
<pre><code>praat praatsauce.praat params.csv</code></pre>
</section>
<section id="parameters" class="level2">
<h2 class="anchored" data-anchor-id="parameters">Parameters</h2>
<p>The provided <code>params.csv</code> file has three “columns”:</p>
<ul>
<li><code>variable</code> the name of the parameter</li>
<li><code>input</code> the value for this parameter</li>
<li><code>comment</code> a brief description of the parameter</li>
</ul>
<p>Here, we provide a little more detail about each parameter.</p>
<ul>
<li><code>inputDir</code> is the directory where your sound files are located.</li>
<li><code>outputDir</code> is the directory where your output file should be saved. The default value is <code>.</code>, i.e.&nbsp;the same directory as where <code>praatsauce.praat</code> is located.</li>
<li><code>outputFile</code> is the name of the output file. Default is <code>out.tsv</code>.</li>
<li><code>channel</code> is the channel you want to analyze. Default is <code>1</code>, i.e.&nbsp;the first channel. If your sound files have multiple channels, fx if the audio is stereo or you have an EGG channel, one of them is extracted and used for processing. You can input <code>0</code> if you want to use both channels of a stereo file.</li>
<li><code>intervalEquidistant</code> If measures should be taken at equidistant intervals, how many measures should be taken? This parameter is only relevant if TextGrids are used to determine where to take measures in a sound file. Default is <code>0</code>, in which case measures are taken at fixed intervals.</li>
<li><code>intervalFixed</code> How often should measures be taken (in seconds)? Default is <code>0.005</code>, i.e.&nbsp;every 5 ms. This is more coarse than the VoiceSauce default of taking measures every 1 ms. This should be set to <code>0</code> if you are taking equidistant measures; either <code>intervalEquidistant</code> or <code>intervalFixed</code> should be set to <code>0</code>, otherwise you will see an error message.</li>
<li><code>pitch</code> Should pitch measures be reported in the output file? Default is <code>1</code>, set to <code>0</code> if you are not interested in pitch. Note that pitch will typically be measured anyways, as most of the other measures rely on pitch.</li>
<li><code>formant</code> Should formant measures be reported in the output file? Default is <code>1</code>, set to <code>0</code> if you are not interested in formants. Note that formants will often be measured anyways, as many of the other measures rely on formants.</li>
<li><code>harmonicAmplitude</code> Should corrected harmonic amplitude measures (H1*, H2*, H4*, A1*, A2*, A3*, H2K, H5K) be reported in the output file? Default is <code>1</code>, set to <code>0</code> if you are not interested in corrected harmonic amplitudes. Note that corrected harmonic amplitudes are calculated anyways if you want spectral slope measures.</li>
<li><code>harmonicAmplitudeUncorrected</code> Should uncorrected harmonic amplitude measures (H1, H2, H4, A1, A2, A3) be reported in the output file? Default is <code>1</code>, set to <code>0</code> if you are not interested in uncorrected harmonic amplitudes. Note that uncorrected harmonic amplitudes are calculated anyways if you want corrected harmonic amplitudes.</li>
<li><code>bw</code> Should formant bandwidths be reported? Default is <code>1</code>, set to <code>0</code> if you are not interested in bandwidths. Note that bandwidths will be measured/estimated anyways if you want corrected harmonic amplitudes.</li>
<li><code>bwHawksMiller</code> Should formant bandwidths be estimated using the Hawks–Miller formula <span class="citation" data-cites="hawks1995">(<a href="#ref-hawks1995" role="doc-biblioref">Hawks &amp; Miller 1995</a>)</span>? Default is <code>1</code>, set to <code>0</code> if you want to use Praat’s empirical bandwidth measures for harmonic amplitude corrections.</li>
<li><code>slope</code> Should corrected spectral slope measures (H1*-H2*, H2*-H4*, H1*-A1*, H1*-A2*, H1*-A3*, H2K-H5K) be reported? Default is <code>1</code>, set to <code>0</code> if you are not interested in corrected spectral slope measures.</li>
<li><code>slopeUncorrected</code> Should corrected spectral slope measures (H1-H2, H2-H4, H1-A1, H1-A2, H1-A3) be reported? Default is <code>1</code>, set to <code>0</code> if you are not interested in uncorrected spectral slope measures.</li>
<li><code>cpp</code> Should ceptral peak prominence (CPP) measures be reported? Default is <code>1</code>, set to <code>0</code> if you are not interested in CPP.</li>
<li><code>hnr</code> Should harmonics-to-noise ratio (HNR) measures be reported? Default is <code>1</code>, set to <code>0</code> if you are not interested in HNR.</li>
<li><code>intensity</code> Should intensity (root-mean-squared amplitude) measures be reported? Default is <code>1</code>, set to <code>0</code> if you are not interested in intensity.</li>
<li><code>soe</code> Should strength of (harmonic) excitation (SoE) measures be reported? Default is <code>1</code>, set to <code>0</code> if you are not interested in SoE.</li>
<li><code>resample16khz</code> Should audio be resampled to 16 kHz? Default is <code>0</code>, set to <code>1</code> if you want resampling. This may speed up the processing of some measures, and is otherwise unlikely to influence the results much.</li>
<li><code>windowLength</code> Length of the analysis window for taking formant measurements and generating spectrograms in seconds. Default is <code>0.025</code>, i.e.&nbsp;25 ms.</li>
<li><code>f0min</code> Pitch floor, minimum frequency in Hz to look for when estimating pitch. Default is <code>50</code>. Note that the output may have some pitch measures below <code>f0min</code> if Praat’s algorithm for removing octave jumps is used.</li>
<li><code>f0max</code> Pitch ceiling, maximum frequency in Hz. to look for when estimating pitch. Default is <code>300</code>. Note that the output may have some pitch measures above <code>f0max</code> if Praat’s algorithm for removing octave jumps is used.</li>
<li><code>pitchMethod</code> Which algorithm should be used for measuring pitch? The default value is <code>0</code>, in which case the filtered autocorrelation method is used; alternatives are <code>1</code> for raw crosscorrelation and <code>2</code> for raw autocorrelation.</li>
<li><code>pitchWindowShape</code> Which analysis window shape should be used for pitch estimation. The default value is <code>0</code>, in which case a Hanning window is used; the alternative is <code>1</code>, in which case a Gaussian window is used. This controls the <code>Very accurate</code> setting in Praat’s pitch tracking options windows; Gaussian windows are considered “very accurate”, but are not used by default, as they are slower. In practice, the difference between the two settings appears to be marginal.</li>
<li><code>pitchMaxNoCandidates</code> How many pitch candidates should be estimated? Default is <code>15</code>.</li>
<li><code>silenceThreshold</code> What should be the silence threshold when measuring pitch? Default is <code>0.01</code>, frames that do not contain amplitude values above this threshold relative to the global maximum are considered silent and thus not tracked.</li>
<li><code>voicingThreshold</code> Fractional strength of pitch candidates in the autocorrelation or crosscorrelation function required for a frame to be considered voice. The default is <code>0</code>, in which case the value will be the Praat default for the chosen <code>pitchMethod</code>, i.e.&nbsp;<code>0.5</code> when filtered autocorrelation is used and <code>0.55</code> when raw crosscorrelation is used. With a higher <code>voicingThreshold</code>, more pitch candidates will be considered silent.</li>
<li><code>octaveCost</code> How much should high frequency pitch candidates be favored in terms of fractional strength of candidates in the autocorrelation or crosscorrelation function per octave; higher values will favor high pitch candidates more. The default is <code>0</code>, in which case the value will be the Praat default for the chosen <code>pitchMethod</code>, i.e.&nbsp;<code>0.055</code> when filtered autocorrelation is used and <code>0.01</code> when raw crosscorrelation is used.</li>
<li><code>octaveJumpCost</code> How much should sudden pitch changes be disfavored in terms of fractional strenth of candidates in the autocorrelation or crosscorrelation function. Default is <code>0.35</code>; increasing this value will reduce the number of octave jumps.</li>
<li><code>voicedUnvoicedCost</code> How much should transitions from voiced to voiceless frames be disfavored in terms of fractional strength of candidates in the autocorrelation or crosscorrelation function. The default is <code>0.14</code>; increasing this value will reduce the number of transitions.</li>
<li><code>killOctaveJumps</code> Should Praat’s algorithm for removing octave jumps be applied? Default is <code>0</code>, set to <code>1</code> if you want to use this algorithm. Note that this can have unwanted and unexpected consequences if analyzing full sound files instead of individual tokens.</li>
<li><code>maxNumFormants</code> How many formants should be estimated? Default is <code>5</code>. In any case, only three formants are reported.</li>
<li><code>preEmphFrom</code> Pre-emphasize from which frequency when estimating formants? Default is <code>50</code>.</li>
<li><code>f1ref</code> Reference F1 value used for formant tracking. Default is <code>500</code>.</li>
<li><code>f2ref</code> Reference F2 value used for formant tracking. Default is <code>1500</code>.</li>
<li><code>f3ref</code> Reference F3 value used for formant tracking. Default is <code>2500</code>.</li>
<li><code>maxFormantHz</code> Frequency ceiling when tracking formants. Default is <code>5000</code>.</li>
<li><code>pitchSynchronous</code> Should spectral slope measures be taken using pitch synchronous window length, i.e.&nbsp;with a window length corresponding to 3 glottal pulses? Default is <code>0</code>, in which case window length is constant; set to <code>1</code> to get pitch synchronous window length. This will be somewhat slower if analyzing individual tokens and somewhat faster if analyzing full sound files. The difference appears to be marginal.</li>
<li><code>cppTrendType</code> Which type of regression model should be used to calculate CPP? Default is <code>0</code>, in which case an exponential decay model is used; change to <code>1</code> to use linear regression.</li>
<li><code>cppFast</code> How should the regression model used to calculate CPP be fitted? Default is <code>1</code>, which corresponds to incomplete Thiel regression; the alternative is <code>0</code>, which uses Thiel’s robust line fit, which is more robust but significantly slower.</li>
<li><code>pitchSave</code> Should pitch files be written to disk? Default is <code>0</code>, change to <code>1</code> if you want to store the resulting pitch files.</li>
<li><code>pitchSaveDir</code> If pitch files are written to disk, where should they be saved?</li>
<li><code>pitchRead</code> Should existing pitch files be used? Default is <code>0</code>, change to <code>1</code> if you have existing pitch files which you want to use.</li>
<li><code>pitchSaveDir</code> If existing pitch files should be used, where are they saved?</li>
<li><code>formantSave</code> Should formant files be written to disk? Default is <code>0</code>, change to <code>1</code> if you want to store the resulting formant files.</li>
<li><code>formantSaveDir</code> If formant files are written to disk, where should they be saved?</li>
<li><code>formantRead</code> Should existing formant files be used? Default is <code>0</code>, change to <code>1</code> if you have existing formant files which you want to use.</li>
<li><code>formantSaveDir</code> If existing formant files should be used, where are they saved?</li>
<li><code>useTextGrid</code> Should TextGrids be used to determine where in a sound file to take measures? Default is <code>0</code>, i.e.&nbsp;measures are taken over the entire sound file. Set to <code>1</code> if you wish to take measures only from select parts of sound files based on information in TextGrids.</li>
<li><code>tgDir</code> is the directory where your TextGrids are located (if <code>useTextGrid</code> is set to <code>1</code>).</li>
<li><code>filelist</code> Path to a text file which specifies which sound files to analyze. Should be a plain text file where each line is a relative path to a sound file. These paths are relative to <code>inputDir</code>. By default this argument is ignored, replace <code>0</code> with a path if you want to use it.</li>
<li><code>intervalTier</code>. If using a TextGrid, which is the interval tier of interest? Default is <code>1</code>.</li>
<li><code>includeTheseLabels</code>. If using a TextGrid, the code will search for intervals with these labels. Should be a well-formed regex – the default is <code>^()!\s*$</code> which refers to any interval that isn’t empty.</li>
</ul>
</section>
<section id="output" class="level2">
<h2 class="anchored" data-anchor-id="output">Output</h2>
<p>The output of PraatSauce is a tab-separated text file which maximally looks something like this:</p>
<pre><code>file    label   t   f0  F1  F2  F3  H1c H2c H4c A1c A2c A3c H2Ku    H5Ku    H1u H2u H4u...
1.wav   b   0.621   0   1798.185    2299.12 3370.494    0   0   0   -42.67060159300069  -37.532...
 1.wav  b   0.626   0   1798.185    2299.12 3370.494    0   0   0   -42.67060159300069  -37.5...</code></pre>
<p>It includes a column with a file name, a column with an interval label if TextGrids are used to determine intervals to analyze, a column giving the time stamp where the measures is taken, and columns for each measure at that time.</p>
</section>
<section id="details" class="level2">
<h2 class="anchored" data-anchor-id="details">Details</h2>
<p><strong>Pitch</strong> (<span class="math inline">\(F_0\)</span>) can be measured either 1) using Praat’s filtered autocorrelation method, which implements <span class="citation" data-cites="boersma1993">Boersma (<a href="#ref-boersma1993" role="doc-biblioref">1993</a>)</span>‘s autocorrelation method after low-pass filtering the signal, 1) the ’raw’ autocorrelation method which does not low-pass filter the signal or 3) the raw crosscorrelation which implements a similar routine based on crosscorrelating the signal without applying a low-pass filter. As discussed <a href="https://www.fon.hum.uva.nl/praat/manual/how_to_choose_a_pitch_analysis_method.html" target="_blank">here</a>, filtered autocorrelation is currently considered the state-of-the-art method for measuring intonation in Praat, while raw crosscorrelation is considered state of the art particularly for Praat’s internal voice analysis tools. Praatsauce users can toggle all the usual parameters, which mostly follow the Praat defaults, except for the “silence threshold” parameter which is by default significantly reduced in Praatsauce for better performance near consonant boundaries and in sound files with relatively low volume, and the floor and ceiling parameters which are set to a rather more narrow range in Praatsauce. Good pitch floor and ceiling settings are important and these settings have big downstream consequences on many of the measures estimated by Praatsauce. We recommend setting them on a speaker-by-speaker basis. The <code>Kill octave jumps</code> routine is optionally run on the resulting <code>Pitch</code> object. Praatsauce has the option to save the <code>Pitch</code> objects to disk, allowing users to potentially hand-edit them and then using these edited objects to re-run Praatsauce. See <code>get_pitch.praat</code>.</p>
<p><strong>Formants</strong> (<span class="math inline">\(F_1\)</span>, <span class="math inline">\(F_2\)</span>, <span class="math inline">\(F_3\)</span>) are measured using Praat’s implementation of Burg’s <span class="citation" data-cites="burg">(<a href="#ref-burg" role="doc-biblioref">1975</a>)</span> algorithm. The <code>Track</code> routine, which implements a Viterbi algorithm explained <a href="https://fon.hum.uva.nl/praat/manual/Formant__Track___.html" target="_blank">here</a>, is run on the resulting <code>Formant</code> object with user-specified formant reference values. See <code>get_formants.praat</code>. As with <span class="math inline">\(F_0\)</span>, poor formant tracking will have important downstream consequences for other measures, and Praatsauce has the option to save the <code>Formant</code> objects to disk, allowing users to potentially hand-edit them and use the edited objects to re-run Praatsauce (although this is rather less intuitive than is the case for pitch). When possible, it is probably a good idea to set vowel-specific formant reference values, although we recognize that this is often not feasible.</p>
<p><strong>Formant bandwidths</strong> (<span class="math inline">\(B_1\)</span>, <span class="math inline">\(B_2\)</span>, <span class="math inline">\(B_3\)</span>) are either empirical bandwidths returned by the formant tracking process outlined above (see <code>get_formants.praat</code>), or bandwidths estimated from formants scaled by pitch according to the procedure outlined by <span class="citation" data-cites="hawks1995">Hawks &amp; Miller (<a href="#ref-hawks1995" role="doc-biblioref">1995</a>)</span> (see <code>get_bwHawksMiller.praat</code>). Our experience is that the estimation of harmonic amplitudes is rather less stable when using Praat’s empirical bandwidths.</p>
<p><strong>Harmonic amplitudes</strong> are calculated by generating long-term spectra (by default narrowband spectra from 25 ms Gaussian windows) with a frequency ceiling of 5500 Hz for each time step with a valid pitch measure. By default, the spectra are narrowband spectra from 25 ms Gaussian windows, but it is also possible to determine the window length pitch-synchronously to correspond to three glottal cycles. <span class="math inline">\(H_1\)</span>, the amplitude of the first harmonic, is determined as the energy peak within <span class="math inline">\(F_0\pm\frac{1}{10}F_0\)</span> Hz, where <span class="math inline">\(F_0\)</span> is the fundamental frequency measure returned for any given time step; <span class="math inline">\(H_2\)</span>, the amplitude of the second harmonic, is the energy peak within <span class="math inline">\(2F_0\pm\frac{1}{10}F_0\)</span> Hz; and <span class="math inline">\(H_4\)</span>, the amplitude of the fourth harmonic, is the energy peak within <span class="math inline">\(4F_0\pm\frac{1}{10}F_0\)</span> Hz. <span class="math inline">\(A_1\)</span>, the amplitude of the harmonic nearest <span class="math inline">\(F_1\)</span>, is determined as the energy peak within <span class="math inline">\(F1\pm\frac{1}{5}F1\)</span> Hz, <span class="math inline">\(A_2\)</span> is determined as the energy peak within <span class="math inline">\(F2\pm\frac{1}{10}F2\)</span> Hz, and <span class="math inline">\(A_3\)</span> is determined as the energy peak within <span class="math inline">\(F3\pm\frac{1}{10}F3\)</span> Hz, where <span class="math inline">\(F_n\)</span> is the <span class="math inline">\(n\)</span>th formant measure returned for any given time step. <span class="math inline">\(H_{2K}\)</span>, the amplitude of the harmonic nearest 2000 Hz, is determined as the energy peak within <span class="math inline">\(2000\pm F_0\)</span> Hz, and <span class="math inline">\(H_{5K}\)</span>, the amplitude of the harmonic nearest 5000 Hz, is determined as the energy peak within <span class="math inline">\(5000\pm F_0\)</span> Hz. See <code>get_spectralMeasures.praat</code>. <span class="math inline">\(H_1^*\)</span>, <span class="math inline">\(H_2^*\)</span>, <span class="math inline">\(H_4^*\)</span>, <span class="math inline">\(A_1^*\)</span>, and <span class="math inline">\(A_2^*\)</span> are corrected for the influence of <span class="math inline">\(F_1\)</span> and <span class="math inline">\(F_2\)</span> following the formula given by <span class="citation" data-cites="iseli2007">Iseli, Shue &amp; Alwan (<a href="#ref-iseli2007" role="doc-biblioref">2007</a>)</span>, while <span class="math inline">\(A_3^*\)</span> is corrected for the influence of <span class="math inline">\(F_1\)</span>, <span class="math inline">\(F_2\)</span>, and <span class="math inline">\(F_3\)</span> (see <code>correctIseli.praat</code>). <span class="math inline">\(H_{2K}\)</span> and <span class="math inline">\(H_{5K}\)</span> are not corrected.</p>
<p><strong>Spectral slope</strong> measures are straightforward: <span class="math inline">\(H_1^*-H_2^*\)</span> is the difference between <span class="math inline">\(H_1^*\)</span> and <span class="math inline">\(H_2^*\)</span> etc. PraatSauce returns the standard corrected measures <span class="math inline">\(H_1^*-H_2^*\)</span>, <span class="math inline">\(H_2^*-H_4^*\)</span>, <span class="math inline">\(H_1^*-A_1^*\)</span>, <span class="math inline">\(H_1^*-A_2^*\)</span>, <span class="math inline">\(H_1^*-A_3^*\)</span>, and the uncorrected measures <span class="math inline">\(H_1-H_2\)</span>, <span class="math inline">\(H_2-H_4\)</span>, <span class="math inline">\(H_1-A_1\)</span>, <span class="math inline">\(H_1-A_2\)</span>, <span class="math inline">\(H_1-A_3\)</span>, and <span class="math inline">\(H_{2K}-H_{5K}\)</span>. It is not totally straightforward how to implement correction for <span class="math inline">\(H_{2K}-H_{5K}\)</span>, which is why we don’t do it, but note that other uncorrected slope measures are only returned to facilitate comparison – it is certainly not recommended to use them for analysis. See <code>get_spectralMeasures.praat</code>.</p>
<p><strong>Ceptral peak prominence</strong> measures are calculated by generating power cepstra with a frequency ceiling of 5000 Hz for each time step, fitting regression lines to each cepstrum (either linear or exponential), and determining how much the cepstral peak deviates from the regression line. This is the standard procedure of Praat’s <code>Get peak prominence</code> routine. Note that <span class="citation" data-cites="hillenbrand1994">Hillenbrand, Cleveland &amp; Erickson (<a href="#ref-hillenbrand1994" role="doc-biblioref">1994</a>)</span> and VoiceSauce <span class="citation" data-cites="voicesauce">(<a href="#ref-voicesauce" role="doc-biblioref">Shue et al. 2011</a>)</span> determine the peak prominence by comparing with a linear regression line, but the default in Praat and Praatsauce is to fit an exponential regression; the theoretical arguments for this are laid out here <a href="https://www.fon.hum.uva.nl/praat/manual/PowerCepstrum__Get_peak_prominence___.html" target="_blank">here</a>, but we are not aware of any studies that explicitly compare the suitability of using linear <em>versus</em> exponential regression for computing CPP. See <code>get_CPP.praat</code>.</p>
<p><strong>Harmonics-to-noise ratio</strong> measures are calculated using Praat’s cross-correlation method (a version of <span class="citation" data-cites="boersma1993">Boersma (<a href="#ref-boersma1993" role="doc-biblioref">1993</a>)</span>’s algorithm) which estimates the relative height of the cross-correlation peak (theoretically corresponding to the amplitude of the fundamental frequency). Harmonics-to-noise ratios are taken from different low pass filtered versions of the sound file: <span class="math inline">\(HNR_{500}\)</span>, <span class="math inline">\(HNR_{1500}\)</span>, <span class="math inline">\(HNR_{2500}\)</span>, and <span class="math inline">\(HNR_{3500}\)</span> use low pass filters of 500, 1500, 2500, and 3500 Hz, respectively. See <code>get_HNR.praat</code>.</p>
<p><strong>Intensity</strong> measures, corresponding to the moving root-mean-squared amplitude, are calculated using Praat’s <code>To Intensity</code> procedure. See <code>get_intensity.praat</code>.</p>
<p><strong>Strength of excitation</strong> measures are calculated by downsampling the speech signal, taking the difference of this signal <span class="math inline">\(x[n] = s[n] - s[n-1]\)</span>, and passing it through a cascade of two zero-frequency filters of the form</p>
<p><span class="math display">\[
y_i[n] = - \sum_{k=1}^2 a_k y_i [n-k] + x[n]
\]</span></p>
<p>At each step, we apply a trend removal procedure by subtracting the moving average of a window of size <span class="math inline">\(N\)</span> corresponding to three average pitch cycles from the filtered signal, giving the output</p>
<p><span class="math display">\[
y_2[n] = y_1[n] - \frac{1}{2N+1} \sum_{m=-N}^N y_1[n + m]
\]</span></p>
<p>We find the positive-to-negative zero crossings in the output signal using Praat’s <code>To PointProcess (zeros)</code> routine, and calculate the slope in the immediate vicinity of these zero crossings. This mostly follows the procedure described by <span class="citation" data-cites="yegnanarayana2009">Yegnanarayana &amp; Murty (<a href="#ref-yegnanarayana2009" role="doc-biblioref">2009</a>)</span> and <span class="citation" data-cites="mittal2014">Mittal, Yegnanarayana &amp; Bhaskararao (<a href="#ref-mittal2014" role="doc-biblioref">2014</a>)</span> and implemented in VoiceSauce <span class="citation" data-cites="voicesauce">(<a href="#ref-voicesauce" role="doc-biblioref">Shue et al. 2011</a>)</span>, although the version here is somewhat simplified, as the moving average window size <span class="math inline">\(N\)</span> used for trend removal is determined globally from the interval or sound file rather than locally based on pitch. This does not appear to have a major influence on the results, but this should be tested further. See <code>get_SoE.praat</code>.</p>
<p>The <strong>time domain</strong> of PraatSauce output looks a little goofy. In order to speed up the processing, we did our best to ‘vectorize’ all the operations in PraatSauce by using Praat’s tabulating functions instead of e.g.&nbsp;querying the pitch value for each time step in a loop, as was done in the previous version of PraatSauce. However, tabulating means that the time series for each measure will differ – the start and end point of a table will depend on the window size used for calculating the measure, which is different for each measure, and is further rounded in some esoteric fashion that is difficult to complete figure out. We solve this by taking whichever measure has the most time points as the standards, and padding other time series with zeros, see <code>zeroPadding.praat</code>.</p>
<p><strong>A note on smoothing</strong>: VoiceSauce has a smoothing parameter, and by default smooths harmonic amplitudes and <span class="math inline">\(F_0\)</span>. Apparently spectral slope measures are computed using the smoothed harmonic amplitudes, and the spectral slope measures are then smoothed <em>again</em>. PraatSauce does not do any smoothing – we leave it up to the user how or if they choose to smoothe the measures. This means that PraatSauce output will look a lot more jagged than VoiceSauce output (partially by design).</p>
</section>
<section id="workflow-in-r" class="level2">
<h2 class="anchored" data-anchor-id="workflow-in-r">Workflow in R</h2>
<p>You can use whichever analysis pipeline you prefer, but if you do your analysis in R, note that we have a few convenience tools available as part of an in-development R library called <code>sauceshelf</code>. <code>sauceshelf</code> can be downloaded like so:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">'rpuggaardrode/sauceshelf'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>There is a function available, <code>praatsauce()</code>, which generates a parameters file using the arguments passed on, runs the PraatSauce scripts, and reads in the resulting output as a data frame. <code>praatsauce()</code> The function can be a little finicky for various reasons, but has been tested on both Windows and UNIX systems. Feel free to reach out if you can’t get it to work.</p>
<p>Other functions available in <code>sauceshelf</code> are</p>
<ul>
<li><code>make_params()</code>, which will generate a valid parameters file to use with PraatSauce</li>
<li><code>load_sauce()</code>, which will read PraatSauce output as a well-formatted data frame</li>
<li><code>sauce2ssff()</code> which converts a data frame with PraatSauce output into SSFF files if you are working with the <a href="https://rpuggaardrode.github.io/emuintro/">EMU-SDMS infrastructure</a>.</li>
</ul>
<p><code>sauceshelf</code> also provides various R-internal ways to estimate the measures returned by Praatsauce, and a framework for mixing and matching different sources, i.e.&nbsp;to estimate pitch and formants using Praat, and harmonic amplitudes and spectral slope using R based on the results from Praat. One method which we’ve tentatively found to work well and to speed up processing is to estimate harmonic amplitudes, spectral slope, and SoE in R and all other measures in Praat.</p>
</section>
<section id="references" class="level2 unnumbered">


</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-boersma1993" class="csl-entry" role="listitem">
Boersma, Paul. 1993. Accurate short-term analysis of the fundamental frequency and the harmonics-to-noise ratio of a sampled sound. <em>Institute of Phonetic Sciences, University of Amsterdam, Proceedings</em> 17, 97–110.
</div>
<div id="ref-burg" class="csl-entry" role="listitem">
Burg, John Parker. 1975. Maximum entropy spectral analysis. PhD dissertation, Stanford University.
</div>
<div id="ref-hawks1995" class="csl-entry" role="listitem">
Hawks, John W. &amp; James D. Miller. 1995. A formant bandwidth estimation procedure for vowel synthesis. <em>Journal of the Acoustical Society of America</em> 97(2), 1343–1344. doi:<a href="https://doi.org/10.1121/1.412986">10.1121/1.412986</a>.
</div>
<div id="ref-hillenbrand1994" class="csl-entry" role="listitem">
Hillenbrand, James, Ronald A. Cleveland &amp; Robert L. Erickson. 1994. Acoustic correlates of breathy vocal quality. <em>Journal of Speech, Language, and Hearing Research</em> 37(4), 769–778. doi:<a href="https://doi.org/10.1044/jshr.3704.769">10.1044/jshr.3704.769</a>.
</div>
<div id="ref-iseli2007" class="csl-entry" role="listitem">
Iseli, Markus, Yen-Liang Shue &amp; Abeer Alwan. 2007. Age, sex, and vowel dependencies of acoustic measures related to the voice source. <em>Journal of the Acoustical Society of America</em> 121(4), 2283–2295. doi:<a href="https://doi.org/10.1121/1.2697522">10.1121/1.2697522</a>.
</div>
<div id="ref-mittal2014" class="csl-entry" role="listitem">
Mittal, Vinay Kumar, B. Yegnanarayana &amp; Peri Bhaskararao. 2014. Study of the effects of vocal tract constriction on glottal vibration. <em>Journal of the Acoustical Society of America</em> 136(4), 1932–1941. doi:<a href="https://doi.org/10.1121/1.4894789">10.1121/1.4894789</a>.
</div>
<div id="ref-voicesauce" class="csl-entry" role="listitem">
Shue, Yen-Liang, Patricia A. Keating, Chad Vicenik &amp; Kristine Yu. 2011. <span>VoiceSauce</span>. <span>A</span> program for voice analysis. <em>Proceedings of the 17th <span>International</span> <span>Congress</span> of <span>Phonetic</span> <span>Sciences</span></em>, 1846–1849. Hong Kong.
</div>
<div id="ref-yegnanarayana2009" class="csl-entry" role="listitem">
Yegnanarayana, B. &amp; K. Sri Rama Murty. 2009. Event-based instantaneous fundamental frequency estimation from speech signals. <em>IEEE Transactions on Audio, Speech, and Language Processing</em> 17(4), 614–624. doi:<a href="https://doi.org/10.1109/TASL.2008.2012194">10.1109/TASL.2008.2012194</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>